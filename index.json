[{"categories":null,"contents":"In the quest to enhance neurorehabilitation, our team at Cairo University, is pioneering a project that integrates the immersive world of Virtual Reality (VR) with the groundbreaking potential of Brain-Computer Interface (BCI) systems. This initiative is not just a testament to technological innovation but also a beacon of hope for individuals suffering from the debilitating effects of stroke and brain injuries. We invite esteemed colleagues and professors to explore the nuances and progress of our endeavor as we apply for further study and research opportunities.\nGlobally, stroke and brain injuries are leading causes of severe motor disabilities, leaving millions in need of effective rehabilitation strategies. Traditional therapies often fall short in providing the engagement and individual adaptation necessary for optimal recovery. Our project is born from the urgent need for solutions that are not only effective but also personalized and engaging, using VR and BCI as tools to revolutionize the recovery process.\nAt the heart of our initiative is the synergy between VR and BCI technologies. We are developing an immersive VR game that simulates hiking and other walking activities, designed to motivate and engage users in a compelling rehabilitation journey. The key to this immersive experience is the integration of a Brain-Computer Interface system, which we are currently in the research phase of developing. Our focus is on designing robust motor imagery classifiers that will accurately interpret the user\u0026rsquo;s intentions, translating thoughts into real-time feedback within the virtual environment, thereby enhancing neuroplasticity and functional recovery.\nA critical element of our BCI system is the OpenBCI Cyton board, an adaptable and powerful tool for biosignal processing. We recently discovered a Cyton board in the rehabilitation lab at Cairo University, and we are in the process of repairing and customizing it to fit our project\u0026rsquo;s needs. This endeavor exemplifies our commitment to resourcefulness and innovation, utilizing available technology to its fullest potential.\nTo give a glimpse into the future,here is a generative AI-created image depicting our envisioned VR game design.\nWhile we navigate the complexities of developing accurate motor imagery classifiers and integrating them with the VR environment, we are also dedicated to ensuring user comfort and adapting the system to individual needs. Our commitment extends beyond technological innovation; we are focused on creating a solution that is accessible, effective, and user-centered. For that we have used a 3D printed prototype that will fit well with VR headsets and also provide us with good signal quality from the motor cortex area. This uses the OpenBCI snap EEG electrodes along with any standard 3.5mm electrode clip.\nOur project is a journey of innovation, collaboration, and determination. As we continue to make strides in VR and BCI integration for neurorehabilitation, we invite our academic and professional community to join us in this exciting venture. Your insights, critiques, and support are crucial as we strive to transform the landscape of rehabilitation for individuals affected by stroke and brain injuries.\nWe welcome discussions, feedback, and collaborations from experts and enthusiasts alike. If you wish to learn more, contribute your expertise, or explore potential research collaborations, please reach out. Together, we can make a significant impact on the future of neurorehabilitation.\n","permalink":"https://www.mngaafar.com/projects/creations/advancing-neurorehabilitation-integrating-brain-computer-interfaces-in-virtual-reality-for-motor-rehabilitation-of-stroke-patients/","tags":["graduation_project"],"title":"Advancing Neurorehabilitation: Integrating Brain Computer Interfaces in Virtual Reality for Motor Rehabilitation of Stroke Patients"},{"categories":null,"contents":"This review delves into the pioneering integration of immersive Virtual Reality (VR) and Brain-Computer Interface (BCI) technologies in neuromotor rehabilitation. Highlighting a significant leap in the realm of therapeutic interventions, the paper, titled \u0026ldquo;Immersive Virtual Reality Games in Neuromotor Rehabilitation with Brain-Computer Interfaces: A Scoping Review,\u0026rdquo; encapsulates an extensive synthesis of current research, offering a comprehensive understanding of the field\u0026rsquo;s trajectory and potential.\nKey takeaways include:\nDemographic Diversity and Wide Age Range: The studies encompass a broad demographic, underscoring VR and BCI\u0026rsquo;s potential across various age groups and health conditions, particularly emphasizing the inclusion of stroke and cerebral palsy patients. Technological Evolution: A shift from traditional CAVE systems to the Oculus Rift marks a significant technological advancement, reflecting user preference and accessibility. Motor Imagery (MI) Paradigm: The unanimous adoption of MI across studies accentuates its critical role in enhancing neuroplasticity and improving rehabilitation outcomes. Design and Engagement: The diverse game design elements, focusing on scoring, embodiment, and customization, demonstrate the versatility of immersive BCI-VR games in addressing motor impairments and engaging users. Future Directions: While revealing promising results, the review also identifies areas needing attention, such as the limited focus on gamification and the predominance of healthy participants, suggesting a pathway for more inclusive and engaging future research. ","permalink":"https://www.mngaafar.com/publications/scoping-review/","tags":["brain computer interface (BCIs)","electroencephalography (EEG)","rehabilitation","upper limb","lower limb","virtual reality (VR)","exergames","video games","motor function","scoping review"],"title":"Scoping Review - Immersive Virtual Reality Games in Neuromotor Rehabilitation with Brain-Computer Interfaces"},{"categories":null,"contents":"In the pursuit of creating a more inclusive world, our team has embarked on a groundbreaking project: the \u0026ldquo;Blind Assistance Image Recognition System.\u0026rdquo; This initiative represents a significant leap forward in assistive technology, aiming to transform the lives of visually impaired individuals by enabling them to understand and interact with their environment more effectively.\nRevolutionizing Perception with ViT-GPT2 Integration\nOur system harnesses the power of the Vision Transformer (ViT) and GPT-2, revolutionizing image interpretation. ViT dissects images into patches, analyzing them for a contextual understanding, while the encoder-decoder architecture of GPT-2 takes these insights and translates them into detailed descriptions. This synergy allows for a nuanced perception of the environment, moving beyond mere object identification to a comprehensive narrative of the scene, significantly enhancing the experience for visually impaired individuals. This integrated approach offers a more profound and contextual understanding than traditional methods, paving the way for a new era in assistive technology.\nKey Advantages of Vision Transformers:\nContextual Understanding: ViT\u0026rsquo;s attention mechanism focuses on pertinent parts of the image, ensuring a detailed and nuanced interpretation. Spatial Hierarchy: By employing positional encodings, ViT maintains the image\u0026rsquo;s spatial relationships, crucial for comprehensive scene understanding. Coherent Descriptions: Integrated with an advanced language model, ViT translates complex visual information into descriptive text that reflects the content and context accurately. L﻿ink to the model: nlpconnect/vit-gpt2-image-captioning · Hugging Face\nOutshining Traditional Methods\nThe choice to employ ViT over multiple CNNs wasn\u0026rsquo;t incidental. Traditional CNNs, while effective, offer a fragmented understanding of scenes. ViT, in contrast, ensures that the generated descriptions are not just a collection of labels but a coherent narrative, enhancing the user\u0026rsquo;s comprehension and interaction with their surroundings.\nTraditional CNNs Output ViT Output Object: Car (x1,y1,x2,y2), Tree (x3,y3,x4,y4) A red car parked under a large oak tree. Object: Person (x5,y5,x6,y6), Dog (x7,y7,x8,y8) A person walking their dog along the riverside. Object: Bicycle (x9,y9,x10,y10), Fence (x11,y11,x12,y12) A bicycle leaning against a wooden fence. Object: Bench (x13,y13,x14,y14), Pond (x15,y15,x16,y16) A bench overlooking a serene pond in the park. Enriching Understanding with Advanced Text-to-Speech\nTo further enhance the system\u0026rsquo;s utility, we\u0026rsquo;ve integrated an advanced Text-to-Speech (TTS) model. This component takes the descriptive text generated from the image recognition process and converts it into spoken words, providing an auditory representation of the visual data. This feature is crucial for visually impaired users, as it translates the detailed visual descriptions into a format they can easily understand and interact with.\nL﻿ink to the TTS model: coqui/XTTS-v2 · Hugging Face\nReal-World Impact and Future Directions\nThis system isn\u0026rsquo;t just a technological marvel; it\u0026rsquo;s a tool for empowerment. By providing visually impaired individuals with a more nuanced and holistic understanding of their environment, we\u0026rsquo;re opening up new avenues for them to navigate and interact with the world. Initially deployed on smartphones, future versions may include wearable devices, further integrating this technology into everyday life seamlessly.\nA Collaborative Journey\nThis project is not the end but the beginning of a journey. We invite academics, engineers, and the visually impaired community to engage with this technology, offer feedback, and suggest improvements. Together, we can refine this system and explore other areas where such sensory augmentation can significantly impact individuals\u0026rsquo; lives.\nIn conclusion, our \u0026ldquo;Blind Assistance Image Recognition System\u0026rdquo; represents an initial stride toward harnessing technology to aid those with visual impairments. While we are just students exploring the possibilities, this project, with its Vision Transformer foundation, aims to contribute positively by offering a tool that might enhance the perception and autonomy of visually impaired individuals. As we continue to learn and develop, we hope our work inspires further innovation and progress in this important field.\nT﻿eam Members: Mohamed Nasser (Me), Maryam Moataz, Zeyad Mansour, Hassan Samy, Abdullah Saeed\n","permalink":"https://www.mngaafar.com/projects/creations/empowering-the-visually-impaired-a-leap-forward-with-vision-transformers/","tags":["artificial_intelligence","computer_vision","assistive_technology"],"title":"Empowering the Visually Impaired: A Leap Forward with Vision Transformers"},{"categories":null,"contents":"Building the CUERT Website with Hugo and Netlify CMS\nAs web development team leader for the Cairo University Eco-Racing Team (CUERT), I wanted to create a website that reflects our innovative spirit and showcases our dedication to sustainable transportation. I chose Hugo and Netlify CMS as the foundation for the project. Here\u0026rsquo;s why:\nSpeed and Performance: Hugo is renowned for its blazingly fast performance, making it ideal for building websites that deliver a great user experience. Developer-Friendly: As a developer myself, I appreciate Hugo\u0026rsquo;s simplicity and flexibility. It gave me full control to customize the site\u0026rsquo;s structure, design, and functionality to our specific needs. Content Management Made Easy: Netlify CMS offers a streamlined way to manage and update website content without needing in-depth coding knowledge. This was important for us since non-technical team members also need to contribute to the website. Project Walkthrough\nHere\u0026rsquo;s a quick overview of the steps involved in building the CUERT website:\nDesigning the Structure: I sketched out the desired website structure and information flow, keeping in mind user experience and the team\u0026rsquo;s goals.\nSetting up Hugo: Installing Hugo and selecting an appropriate theme to kick-start development was a breeze.\nContent and Customization: I customized the theme, designed layouts for different sections of the site (About Us, Projects, News, etc.), and ensured everything reflected the CUERT brand.\nIntegrating Netlify CMS: Connecting Netlify CMS to the site empowered my teammates to easily add or update blog posts, project updates, and more.\nThe Result\nThe resulting website is a testament to the capabilities of Hugo and Netlify CMS. It\u0026rsquo;s a platform we\u0026rsquo;re proud of, and it showcases CUERT\u0026rsquo;s achievements and commitment to innovation.\nLessons Learned\nBuilding this website was a fantastic learning experience. If you\u0026rsquo;re looking for a powerful and flexible website development solution, I recommend exploring Hugo and Netlify CMS.\n","permalink":"https://www.mngaafar.com/projects/creations/my-experience-building-a-fast-and-user-friendly-website-with-hugo-and-netlify-cms/","tags":["web"],"title":"My Experience Building a Fast and User-Friendly Website with Hugo and Netlify CMS"},{"categories":null,"contents":"Addressed pretty significant page load performance issue founde in larger deployments. Eliminates uses of intensive backend query, replacing it with an asynchronous API call against a lucene index. This change reduces page load from from 2+ minutes to nearly instant, with an incredibly responsive UI.\n","permalink":"https://www.mngaafar.com/projects/contributions/deploy-triggers/","tags":["Java","jQuery","REST APIs","Bamboo","JSON"],"title":"Atlassian Deployment Triggers"},{"categories":null,"contents":"","permalink":"https://www.mngaafar.com/projects/contributions/privet/","tags":["techtags","used","in","website"],"title":"Privet"},{"categories":null,"contents":"Shields.io is a massive library of badges that can be inserted into project README\u0026rsquo;s or websites displaying various statuses (code coverage, health, version, etc). Support for docker was missing the current build health, and was a pretty trivial addition.\n","permalink":"https://www.mngaafar.com/projects/contributions/shields-docker/","tags":["Docker","Rest APIs","JavaScript","node.js","JSON"],"title":"Added Docker Build Status Badge to shields.io"},{"categories":null,"contents":"While adding Structured Data to a client\u0026rsquo;s website I found some example JSON that was invalid. Simple contribution to cleanup the user documentation providing syntactically valid JSON documents.\n","permalink":"https://www.mngaafar.com/projects/contributions/schema-org/","tags":["JSON"],"title":"Schema.org Structured Data documentation fixes"},{"categories":null,"contents":"\nTMS Motor Mapping Visualization This pull request introduces a new Motor Mapping Visualization feature to Invesalius, offering enhanced capabilities for visualizing and interacting with Motor Evoked Potential (MEP) data.\nFeatures: Heatmap visualization on brain surface based on Motor evoked potentials Interactive MEP value adjustment and session persistence 4 Customizable colormap ranges Brain surface selection Modifiable gaussian parameters for surface and points interpolation 10 Different colormaps to choose from Quick Runthrough The following animation demonstrates the interactive workflow, allowing for real-time exploration of MEP data and visualization customization.\nShow number of hits Filter Category \u0026ldquo;Language\u0026rdquo; results for \u0026ldquo;1156\u0026rdquo; in Keyword\u0026rsquo;s field. Detailed Feature Screenshots Motor Mapping Color Map Presets MEP Values and Toggle Button Preferences Challenges and Takeaways I have invested a good amount of time during the project start for developing understanding on the architecture of the VTK pipeline and the overall visualization logic in Invesalius. Most of that was done on my own, with a little push from my mentors to fill in the knowledge gaps I had. This really gave me a taste of open source and the need to be self reliant first and foremost before using any of the contributors\u0026rsquo; time. Before GSoC, I had basic knowledge on developing medical visualization software and the complexity it can reach. Through this project, I was able to use VTK and python effectively to build complex and modular logic for brain visualization. Being someone who uses python for everything, I love creating new programs/tools using Python. This project helped me learn a lot about working with pub-sub or event driven architecture in python and also taught me how to work with wxPython GUI framework which is used in many old python applications. My code quality has also improved, thanks to detailed reviews from mentors over the course of this project. Acknowledgements I\u0026rsquo;d like to thank all my mentors for helping me throughout this project. A special shoutout to Renan Matusda and Victor Souza, for their comprehensive code reviews and guidance. It was an honor working with them.\nContributing to Invesalius has been amazing, and I am looking forward to contributing more in the future! I am glad to have worked with such amazing people. I am extremely thankful to Google Summer of Code for providing me with this opportunity to improve my programming skills and learn a lot about open-source development along the way.\nPull Requests https://github.com/invesalius/invesalius3/pull/825\nFuture Work In future iterations, I plan to add a sliding gradient editor for more intuitive color customization and enhance the colorbar for improved range interpretation. The brain projection is not directly projected to the surface and is dependent on the height from the scalp as the point is generated at the coil\u0026rsquo;s center position and not directly on the brain surface, increasing the visualization radius from preferences helps. But it is not ideal. ","permalink":"https://www.mngaafar.com/blog/tms-motor-mapping-and-visualization-google-summer-of-code-2024/","tags":null,"title":"TMS Motor Mapping and Visualization - Google Summer of Code 2024"},{"categories":null,"contents":"Intro Doesn\u0026rsquo;t matter whether it\u0026rsquo;s a CakePHP app for a client, your own personal CMS, or any other web based application. If your passing around passwords or other sensitive info you should really implement SSL. SSL provides 2 main perks to your visitors.\nFirst it encrypts all communication that flies across the web. This prevents curious or devious billies from getting your secrets. Secondly it ensures to the user that your server is in fact who it claims, and not a nasty \u0026lsquo;man in the middle\u0026quot; attack. Finally it gives your site that touch of class\u0026hellip;. which of course a classy person like yourself relies on. Once you implement SSL certificates on your server you\u0026rsquo;ll want to require secure connections using Apache\u0026rsquo;s rewrite module. Now I won\u0026rsquo;t dwell on the creation and signing of certificates, its already well documented. If your just starting out though,heres a few links I recommend;\nCreating self-signed certificates (free, but should only be used internally or for testing, users will; see an \u0026lsquo;Untrusted\u0026quot; warning) Requesting a CA Signed certificate (not free, but the final certificate is trusted and seamless for users) The second link uses the schools internal CA, you will need to pay a public CA like Entrust or Verisign. All of this information is aimed at \u0026rsquo;nix or solaris servers running apache. Why? cause a production windows server is laughable :-p\nNow that you have a certificate, whats next? So there you are you have a shiny new Certificate and Server key, how do you force visitors to your apache driven site to use the SSL? You copied the certificates into the appropite locations right? And you have made the needed changes in httpd.conf right? So now when you view https://example.com you see a \u0026rsquo;trusted\u0026rsquo; warning or your site right? If No to any of these than this article does a pretty good job of outlining those steps.\nThe SSL Works, How do I force connections to use it? First you need to decide if you want to force every page on your site to use SSL, or only a particular sub-domain, or maybe just your admin directory. Since the overhead is minimal there is no harm is forcing the entire domain to leverage SSL, but if it is a self-signed certificate for your personal use than you\u0026rsquo;ll most certainly want to restrict its use to your own areas. This prevents users from seeing that nasty warning \u0026ldquo;This server is not trusted\u0026rdquo; You\u0026rsquo;ll know if your using SSL because the url prefix changes from http to https (s for secure).\nForcing entire domain to use SSL You want any visit, any where to use ssl. This probably the simplest solution. Create or append to your htaccess file in the top directory of your server. Some people use a port check (80 is typically http, while 443 is https) but if you have alernate configs or the user just adds :8080 to the end of the url this method is useless. Instead check whether the https environmental variable is set, if not then redirect.\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://%{SERVER_NAME}$1 \\[R,L\\] Forcing sub-domains to use SSL Maybe you only want mysecretarea.example.com to use SSL, that\u0026rsquo;s easy enough. Its the same premise as above, but you move the htaccess file into the directory that corresponds to the subdomain. Also change the second line like below;\nRewriteCond %{HTTPS} !=on RewriteRule ^(.*)$ https://mysecretarea.%{SERVER_NAME}$1 \\[R,L\\] Forcing a directory to use SSL This method cn get a little hairier if your using aliases or redirects on top of this one. You\u0026rsquo;ll need to consider what order the commands are read. The basic principle is like so. You want all visits to example.com/admin to use ssl. Create a htaccess file in the parent directory. Again will check for the https variable, but this time we also check for the sub-directory to be in the path.\nRewriteCond %{HTTPS} !=on RewriteRule ^/admin/(.*)$ https://%{SERVER_NAME}/admin/$1 \\[R,L\\] ","permalink":"https://www.mngaafar.com/blog/force-ssl/","tags":["apache","apache","redirect","rewrite","ssl","web development"],"title":"My first blog post"},{"categories":null,"contents":"This file exists solely to respond to /resume URL with the related resume layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/resume.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThe canva link is used to embed the resume in the website.\n","permalink":"https://www.mngaafar.com/resume/","tags":null,"title":"Resume"},{"categories":null,"contents":"This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml\n[outputs] home = [\u0026#34;HTML\u0026#34;, \u0026#34;JSON\u0026#34;] Searching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category\n... \u0026#34;contents\u0026#34;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026#34;tags\u0026#34;:{{ .Params.tags | jsonify }}{{end}}, \u0026#34;categories\u0026#34; : {{ .Params.categories | jsonify }}, ... Edit fuse.js options to Search static/js/search.js\nkeys: [ \u0026#34;title\u0026#34;, \u0026#34;contents\u0026#34;, \u0026#34;tags\u0026#34;, \u0026#34;categories\u0026#34; ] ","permalink":"https://www.mngaafar.com/search/","tags":null,"title":"Search Results"}]